{
    "docs": [
        {
            "location": "/",
            "text": "Introduction\n\n\nWelcome to the Terraform & Ansible Introduction lab!\n\n\nIn this lab we will deploy a VM-Series firewall in \nGoogle Cloud Platform\n (GCP) using Terraform.  Once deployed, we will then use \nTerraform\n and \nAnsible\n to manage the configuration of the firewall.  This will include hands-on definition of Terraform plans and Ansible playbooks while exploring the functionality of the Palo Alto Networks Ansible modules and Terraform provider.\n\n\nThe following are NOT goals of this lab:\n\n\n\n\n\n\nShow a realistic deployment of the firewall:\n More realistic deployment would only complicate the provisioning configuration. If you want to see a more realistic deployment of the firewall in GCP, then please refer to the links at the end of this document for examples.\n\n\n\n\n\n\nTeach Google Cloud Platform (GCP) functionality:\n The choice to use GCP for this lab was intended to provide exposure to GCP and its command line utilities.  However, a comprehensive overview of GCP is beyond the scope of this lab.  Many of the concept we'll briefly cover are similar to other public cloud providers.\n\n\n\n\n\n\nRequirements\n\n\n\n\nA laptop with Internet connectivity\n\n\nA Google Cloud Platform \naccount\n\n\nA standards-compliant web browser (Google Chrome recommended)\n\n\nUnderstanding of Linux operating system basics\n\n\nProficiency with a Linux text editor (e.g., vim, nano, or emacs)\n\n\n\n\nAbout This Lab\n\n\n<<<<<<< HEAD\n\n\n* \nQwiklabs:\n This lab is launched using Qwiklabs, which is an online learning environment that provides access to the actual environment you want to learn about, not a simulation or demo environment. Qwiklabs will establish a temporary account in Google Cloud Platform and create a new GCP project to use.  However, this lab may also be used outside of Qwiklabs if you have a have a \nGCP account\n.\n\n\n\n\nTerraform:\n This lab will utilize Terraform for both deploying a VM-Series firewall instances into GCP as well as configuring it once it is deployed.  This will demonstrate the use of the \ngoogle\n Terraform provider and its associated resources for the deployment and then the \npanos\n Terraform provider for the configuration of the VM-Series firewall.\n\n\nAnsible:\n Once the firewall is fully configured we will back out all of the configurations made with Terraform and recreate them using the \nansible-pan\n modules in Ansible.  This will demonstrate the creation of Ansible playbooks and task definitions.\n\n\nGoogle Cloud Shell:\n This lab makes use of the Google Cloud Shell instead of deploying a separate VM hosting the Terraform and Ansible packages. Cloud Shell is an interactive shell environment for Google Cloud Platform. It makes it easy for you to manage your projects and resources without having to install the Google Cloud SDK and other tools on a separate host. With Cloud Shell, the Cloud SDK gcloud command-line tool and other utilities you need are always available when you need them.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npost-sko\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGoogle Cloud SDK:\n The initial configuration of the lab environment utilizes the Google Cloud SDK command line interface to perform tasks such as enabling APIs and establishing credentials.  These tasks could just as easily be accomplished using the GCP web console.  However, familiarity with the CLI commands is useful and presents opportunities for further scripting and automation.",
            "title": "Introduction"
        },
        {
            "location": "/#introduction",
            "text": "Welcome to the Terraform & Ansible Introduction lab!  In this lab we will deploy a VM-Series firewall in  Google Cloud Platform  (GCP) using Terraform.  Once deployed, we will then use  Terraform  and  Ansible  to manage the configuration of the firewall.  This will include hands-on definition of Terraform plans and Ansible playbooks while exploring the functionality of the Palo Alto Networks Ansible modules and Terraform provider.  The following are NOT goals of this lab:    Show a realistic deployment of the firewall:  More realistic deployment would only complicate the provisioning configuration. If you want to see a more realistic deployment of the firewall in GCP, then please refer to the links at the end of this document for examples.    Teach Google Cloud Platform (GCP) functionality:  The choice to use GCP for this lab was intended to provide exposure to GCP and its command line utilities.  However, a comprehensive overview of GCP is beyond the scope of this lab.  Many of the concept we'll briefly cover are similar to other public cloud providers.",
            "title": "Introduction"
        },
        {
            "location": "/#requirements",
            "text": "A laptop with Internet connectivity  A Google Cloud Platform  account  A standards-compliant web browser (Google Chrome recommended)  Understanding of Linux operating system basics  Proficiency with a Linux text editor (e.g., vim, nano, or emacs)",
            "title": "Requirements"
        },
        {
            "location": "/#about-this-lab",
            "text": "<<<<<<< HEAD",
            "title": "About This Lab"
        },
        {
            "location": "/#qwiklabs-this-lab-is-launched-using-qwiklabs-which-is-an-online-learning-environment-that-provides-access-to-the-actual-environment-you-want-to-learn-about-not-a-simulation-or-demo-environment-qwiklabs-will-establish-a-temporary-account-in-google-cloud-platform-and-create-a-new-gcp-project-to-use-however-this-lab-may-also-be-used-outside-of-qwiklabs-if-you-have-a-have-a-gcp-account",
            "text": "Terraform:  This lab will utilize Terraform for both deploying a VM-Series firewall instances into GCP as well as configuring it once it is deployed.  This will demonstrate the use of the  google  Terraform provider and its associated resources for the deployment and then the  panos  Terraform provider for the configuration of the VM-Series firewall.  Ansible:  Once the firewall is fully configured we will back out all of the configurations made with Terraform and recreate them using the  ansible-pan  modules in Ansible.  This will demonstrate the creation of Ansible playbooks and task definitions.  Google Cloud Shell:  This lab makes use of the Google Cloud Shell instead of deploying a separate VM hosting the Terraform and Ansible packages. Cloud Shell is an interactive shell environment for Google Cloud Platform. It makes it easy for you to manage your projects and resources without having to install the Google Cloud SDK and other tools on a separate host. With Cloud Shell, the Cloud SDK gcloud command-line tool and other utilities you need are always available when you need them.        post-sko          Google Cloud SDK:  The initial configuration of the lab environment utilizes the Google Cloud SDK command line interface to perform tasks such as enabling APIs and establishing credentials.  These tasks could just as easily be accomplished using the GCP web console.  However, familiarity with the CLI commands is useful and presents opportunities for further scripting and automation.",
            "title": "* Qwiklabs: This lab is launched using Qwiklabs, which is an online learning environment that provides access to the actual environment you want to learn about, not a simulation or demo environment. Qwiklabs will establish a temporary account in Google Cloud Platform and create a new GCP project to use.  However, this lab may also be used outside of Qwiklabs if you have a have a GCP account."
        },
        {
            "location": "/getting-started/",
            "text": "Getting Started\n\n\nIn this activity you will:\n\n\n<<<<<<< HEAD\n\n Log into Qwiklabs\n\n Launch the lab in Qwiklabs\n\n Create a Linux VM instance\n\n SSH into the Linux VM\n\n\n\n\nWARNING:\n You must use the credentials provided by Qwiklabs for this lab.  Failure to do so may result in charges to your personal Google account.  You should either log out of Google entirely before proceeding or open an Icognito window in the Google Chrome web browser.\n\n\n\n\n\n\nLog into Qwiklabs\n\n\nNavigate to the \nQwiklabs URL\n in your web browser\n\n\nhttps://paloaltonetworks.qwiklab.com\n\n\n\n\nLog in with your Qwiklabs credentials (sign up if you are new to Qwiklabs).  You must use your corporate email address for the username.\n\n\n\nLaunch the lab\n\n\nConfirm that the lab entitled \nIntroduction to Terraform and Ansible\n is listed under \nIn Progress\n on the welcome screen.\n\n\nClick on the \nIntroduction to Terraform and Ansible\n lab to add it to your \nMy Learning\n inventory.\n\n\n\nClick on the \nIntroduction to Terraform and Ansible\n lab in the \nMy Learning\n page.\n\n\n\nClick on \nStart Lab\n in the upper right corner of the main lab page.\n\n\n\nMake note of the \nUsername\n, \nPassword\n, and \nGCP Project ID\n fields that are generated.\n\n\n=======\n\n Log into Google Cloud Platform\n\n Launch the Google Cloud Shell\n* Create a new GCP project\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npost-sko\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLog into Google Cloud Platform\n\n\nUsing your web browser, navigate to \nhttps://console.cloud.google.com\n.\n\n\nLog in using your Google Cloud Platform credentials.  If you do not have a GCP account you can create one at \nhttps://cloud.google.com/free\n.\n\n\n\nClick \nAccept\n on the logon banner page to accept the Terms of Service. \n(New accounts only)\n\n\n\n\nUpdate your account recovery details and click \nDone\n. \n(New accounts only)\n\n\n\n\nSelect your country, opt out of email updates, and accept the updated Terms of Service and click \nAccept\n. \n(New accounts only)\n\n\n\n\nCreate a new Linux VM instance\n\n\nScroll down in the left-hand navigation menu and select \nCompute Engine > VM instances\n.\n\n\n\nIn the VM instances screen, click \nCreate\n to being the VM creation process.\n\n\n\nGive the VM instance a name of your choice.  Select the \nus-central1 (Iowa)\n region and select any one of the four zones available.\n\n\n\nScroll down to the \nAccess scopes\n section and select \nAllow full access to all Cloud APIs\n.  Then click \nCreate\n to launch the VM instance.\n\n\n\nOnce the Linux VM is up and running you can connect to it by clicking \nSSH\n in the instance list (You may need to click \nHIDE INFO PANEL\n in the upper left first).\n\n\n\n<<<<<<< HEAD\nGoogle Cloud will create an SSH key pair and distribute it to the newly created Linux VM. It will then open an SSH window into it.\n\n\n\nYou are now ready to proceed with the lab configuration!\n\n\nYou are now ready to use the Cloud Shell.\n\n\n\n\nCreate a new GCP project\n\n\nIn the Cloud Shell window, create a new project using the following \ngcloud projects\n command.\n\n\n$ gcloud projects create terraform-ansible-lab\n\n\n\n\nThen we'll need to change the GCP configuration to utilize this project with the following \ngcloud config\n command.\n\n\n$ gcloud config set project terraform-ansible-lab\n\n\n\n\nConfirm the configuration details with the following \ngcloud config\n command.\n\n\n$ gcloud config list\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npost-sko",
            "title": "Getting Started"
        },
        {
            "location": "/getting-started/#getting-started",
            "text": "In this activity you will:  <<<<<<< HEAD  Log into Qwiklabs  Launch the lab in Qwiklabs  Create a Linux VM instance  SSH into the Linux VM   WARNING:  You must use the credentials provided by Qwiklabs for this lab.  Failure to do so may result in charges to your personal Google account.  You should either log out of Google entirely before proceeding or open an Icognito window in the Google Chrome web browser.",
            "title": "Getting Started"
        },
        {
            "location": "/getting-started/#log-into-qwiklabs",
            "text": "Navigate to the  Qwiklabs URL  in your web browser  https://paloaltonetworks.qwiklab.com  Log in with your Qwiklabs credentials (sign up if you are new to Qwiklabs).  You must use your corporate email address for the username.",
            "title": "Log into Qwiklabs"
        },
        {
            "location": "/getting-started/#launch-the-lab",
            "text": "Confirm that the lab entitled  Introduction to Terraform and Ansible  is listed under  In Progress  on the welcome screen.  Click on the  Introduction to Terraform and Ansible  lab to add it to your  My Learning  inventory.  Click on the  Introduction to Terraform and Ansible  lab in the  My Learning  page.  Click on  Start Lab  in the upper right corner of the main lab page.  Make note of the  Username ,  Password , and  GCP Project ID  fields that are generated. \n=======  Log into Google Cloud Platform  Launch the Google Cloud Shell\n* Create a new GCP project         post-sko",
            "title": "Launch the lab"
        },
        {
            "location": "/getting-started/#log-into-google-cloud-platform",
            "text": "Using your web browser, navigate to  https://console.cloud.google.com .  Log in using your Google Cloud Platform credentials.  If you do not have a GCP account you can create one at  https://cloud.google.com/free .  Click  Accept  on the logon banner page to accept the Terms of Service.  (New accounts only)   Update your account recovery details and click  Done .  (New accounts only)   Select your country, opt out of email updates, and accept the updated Terms of Service and click  Accept .  (New accounts only)",
            "title": "Log into Google Cloud Platform"
        },
        {
            "location": "/getting-started/#create-a-new-linux-vm-instance",
            "text": "Scroll down in the left-hand navigation menu and select  Compute Engine > VM instances .  In the VM instances screen, click  Create  to being the VM creation process.  Give the VM instance a name of your choice.  Select the  us-central1 (Iowa)  region and select any one of the four zones available.  Scroll down to the  Access scopes  section and select  Allow full access to all Cloud APIs .  Then click  Create  to launch the VM instance.  Once the Linux VM is up and running you can connect to it by clicking  SSH  in the instance list (You may need to click  HIDE INFO PANEL  in the upper left first).  <<<<<<< HEAD\nGoogle Cloud will create an SSH key pair and distribute it to the newly created Linux VM. It will then open an SSH window into it.",
            "title": "Create a new Linux VM instance"
        },
        {
            "location": "/getting-started/#you-are-now-ready-to-proceed-with-the-lab-configuration",
            "text": "You are now ready to use the Cloud Shell.",
            "title": "You are now ready to proceed with the lab configuration!"
        },
        {
            "location": "/getting-started/#create-a-new-gcp-project",
            "text": "In the Cloud Shell window, create a new project using the following  gcloud projects  command.  $ gcloud projects create terraform-ansible-lab  Then we'll need to change the GCP configuration to utilize this project with the following  gcloud config  command.  $ gcloud config set project terraform-ansible-lab  Confirm the configuration details with the following  gcloud config  command.  $ gcloud config list         post-sko",
            "title": "Create a new GCP project"
        },
        {
            "location": "/configuration/",
            "text": "Configuration\n\n\nIn this activity you will:\n\n\n\n\nDownload the lab repo\n\n\nInstall Terraform and Ansible\n\n\nEnable the Compute Engine API\n\n\nConfigure API credentials\n\n\nConfigure SSH credentials\n\n\n\n\n\n\nNOTE:\n  All of the commands listed within this activity should be executed within the Google Cloud VM we just created - \nnot on your laptop\n.\n\n\n\n\nInstall the git package\n\n\nIn the SSH sessions, type the following command to install the git package.\n\n\n$ sudo apt-get install git\n\n\n\n\nInstall Terraform and Ansible\n\n\nDownload the lab repository to your home directory.\n\n\n$ git clone https://github.com/PaloAltoNetworks/terraform-ansible-intro\n\n\n\n\nChange into the lab directory and run the lab configuration script.  This will install the Terraform binary and the Ansible package.  This may take a few minutes to complete.\n\n\n$ cd terraform-ansible-intro\n$ ./setup\n\n\n\n\nRun the commands below to ensure the Terraform and Ansible binaries are properly installed.  Both commands should display the current version of each executable.\n\n\n$ terraform --version\n$ ansible --version\n\n\n\n\nEnable the Compute Engine API\n\n\nUse the following \ngcloud services\n command to enable the Compute Engine API.  This API will be used by Terraform to deploy the VM-Series instance.\n\n\n$ gcloud services enable compute.googleapis.com\n\n\n\n\nConfigure API credentials\n\n\nUse the following \ngcloud iam\n command to list the default service accounts.\n\n\n$ gcloud iam service-accounts list\n\n\n\n\nUse the following \ngcloud iam\n command to download the credentials for the \nCompute Engine default service account\n using its associated email address (displayed in the output of the previous command).\n\n\n$ gcloud iam service-accounts keys create gcp_compute_key.json --iam-account <EMAIL_ADDRESS>\n\n\n\n\nVerify the JSON credentials file was successfully created.\n\n\n$ cat gcp_compute_key.json\n\n\n\n\nConfigure SSH credentials\n\n\nCreate an SSH key with an empty passphrase and save it in the \n~/.ssh\n directory.\n\n\n$ ssh-keygen -t rsa -b 1024 -N '' -f ~/.ssh/lab_ssh_key\n\n\n\n\n\n\nNOTE:\n GCP has the ability to manage all of its own SSH keys and propagate them automatically to projects and instances.  However, the VM-Series is only able to make use of a single SSH key.  Rather than leverage GCP's SSH key management process, we've created our own SSH key and configured the Compute Engine to use our key exclusively.  When we deploy the VM-Series in the next activity we'll instruct the instance to also use the SSH key we've created.",
            "title": "Configuration"
        },
        {
            "location": "/configuration/#configuration",
            "text": "In this activity you will:   Download the lab repo  Install Terraform and Ansible  Enable the Compute Engine API  Configure API credentials  Configure SSH credentials    NOTE:   All of the commands listed within this activity should be executed within the Google Cloud VM we just created -  not on your laptop .",
            "title": "Configuration"
        },
        {
            "location": "/configuration/#install-the-git-package",
            "text": "In the SSH sessions, type the following command to install the git package.  $ sudo apt-get install git",
            "title": "Install the git package"
        },
        {
            "location": "/configuration/#install-terraform-and-ansible",
            "text": "Download the lab repository to your home directory.  $ git clone https://github.com/PaloAltoNetworks/terraform-ansible-intro  Change into the lab directory and run the lab configuration script.  This will install the Terraform binary and the Ansible package.  This may take a few minutes to complete.  $ cd terraform-ansible-intro\n$ ./setup  Run the commands below to ensure the Terraform and Ansible binaries are properly installed.  Both commands should display the current version of each executable.  $ terraform --version\n$ ansible --version",
            "title": "Install Terraform and Ansible"
        },
        {
            "location": "/configuration/#enable-the-compute-engine-api",
            "text": "Use the following  gcloud services  command to enable the Compute Engine API.  This API will be used by Terraform to deploy the VM-Series instance.  $ gcloud services enable compute.googleapis.com",
            "title": "Enable the Compute Engine API"
        },
        {
            "location": "/configuration/#configure-api-credentials",
            "text": "Use the following  gcloud iam  command to list the default service accounts.  $ gcloud iam service-accounts list  Use the following  gcloud iam  command to download the credentials for the  Compute Engine default service account  using its associated email address (displayed in the output of the previous command).  $ gcloud iam service-accounts keys create gcp_compute_key.json --iam-account <EMAIL_ADDRESS>  Verify the JSON credentials file was successfully created.  $ cat gcp_compute_key.json",
            "title": "Configure API credentials"
        },
        {
            "location": "/configuration/#configure-ssh-credentials",
            "text": "Create an SSH key with an empty passphrase and save it in the  ~/.ssh  directory.  $ ssh-keygen -t rsa -b 1024 -N '' -f ~/.ssh/lab_ssh_key   NOTE:  GCP has the ability to manage all of its own SSH keys and propagate them automatically to projects and instances.  However, the VM-Series is only able to make use of a single SSH key.  Rather than leverage GCP's SSH key management process, we've created our own SSH key and configured the Compute Engine to use our key exclusively.  When we deploy the VM-Series in the next activity we'll instruct the instance to also use the SSH key we've created.",
            "title": "Configure SSH credentials"
        },
        {
            "location": "/deployment/",
            "text": "Deployment\n\n\nIn this activity you will:\n\n\n\n\nDefine the Terraform plan variables\n\n\nInitialize the Terraform providers\n\n\nDeploy the VM-Series firewall\n\n\nUpdate the SSH configs\n\n\nSet the firewall administrative password\n\n\n\n\nDefine the Terraform plan variables\n\n\nChange into the \ndeployment\n directory.\n\n\n$ cd deployment\n\n\n\n\nEdit the file \ngcp_variables.tf\n.  This file contains Terraform variables that will be referenced in other Terraform plan files.\n\n\nReplace the \ndefault\n value for the variable \ngcp_project_id\n with the GCP project you created previously.  Fill in the \ngcp_region\n variable's \ndescription\n and \ndefault\n values with your region of choice.  The current list of available GCP regions may be found at \nhttps://cloud.google.com/about/locations/\n.\n\n\nThe \ngcp_credentials_file\n, and \ngcp_ssh_key\n variables have been pre-populated for you.\n\n\nvariable \"gcp_project_id\" {\n  description = \"GCP Project ID\"\n  type = \"string\"\n  default = \"\"\n}\n\nvariable \"gcp_region\" {\n  description = \"\"\n  type = \"string\"\n  default = \"\"\n}\n\nvariable \"gcp_credentials_file\" {\n  description = \"Full path to the JSON credentials file\"\n  type = \"string\"\n  default = \"../gcp_compute_key.json\"\n}\n\nvariable \"gcp_ssh_key\" {\n  description = \"Full path to the SSH public key file\"\n  type = \"string\"\n  default = \"../../.ssh/lab_ssh_key.pub\"\n}\n\n\n\n\nSave the file and exit the text editor.\n\n\nInitialize the Terraform providers\n\n\nType the following command to initialize any Terraform providers specified in the plan files.\n\n\n$ terraform init\n\n\n\n\nDeploy the VM-Series firewall\n\n\nType the following command to perform a dry-run of the Terraform plan and gather its state data.\n\n\n$ terraform plan\n\n\n\n\nType the following command to execute the Terraform plan.  You can append \n--auto-approve\n to the command in order to avoid the confirmation step.  This will deploy the VM-Series instance in GCP.  This will take a few moments to complete.\n\n\n$ terraform apply\n\n\n\n\nCopy and paste the output fields (in green) into a note or document on your laptop.  You will need this information later.\n\n\nUpdate the SSH config\n\n\nUse the following \ngcloud compute\n command to override the default GCP key management process and utilize our SSH key.\n\n\n$ gcloud compute config-ssh --ssh-key-file=~/.ssh/lab_ssh_key\n\n\n\n\nSet the firewall administrator password\n\n\nUse the \ngcloud compute\n command to get the hostname of the VM-Series firewall instance.\n\n\n$ gcloud compute instances list\n\n\n\n\nSSH into the firewall using the fully qualified hostname of the instance.  You may need to wait a few minutes for the firewall to finish booting up. If you receive a \nConnection refused\n response or are prompted for a password the VM-Series instance has not fully booted yet. Hit \nCtl-C\n and wait few moments before trying again.\n\n\n\n\nNOTE:\n Feel free to read the \nTerraform Background\n section to learn more about Terraform while you're waiting. :-)\n\n\n\n\n$ ssh admin@<INSTANCE>.<ZONE>.<PROJECT>\n\n\n\n\nOnce successfully logged in and presented with a CLI prompt you must set the administrative password for the VM-Series firewall.\n\n\nadmin@PA-VM> configure\nadmin@PA-VM# set mgt-config users admin password\nadmin@PA-VM# commit\nadmin@PA-VM# exit\nadmin@PA-VM> exit\n\n\n\n\nLaunch a separate web browser tab and log into the VM-Series web user interface using the external IP address of the VM-Series instance.\n\n\nYou are now ready to begin the Terraform portion of the lab.",
            "title": "Deployment"
        },
        {
            "location": "/deployment/#deployment",
            "text": "In this activity you will:   Define the Terraform plan variables  Initialize the Terraform providers  Deploy the VM-Series firewall  Update the SSH configs  Set the firewall administrative password",
            "title": "Deployment"
        },
        {
            "location": "/deployment/#define-the-terraform-plan-variables",
            "text": "Change into the  deployment  directory.  $ cd deployment  Edit the file  gcp_variables.tf .  This file contains Terraform variables that will be referenced in other Terraform plan files.  Replace the  default  value for the variable  gcp_project_id  with the GCP project you created previously.  Fill in the  gcp_region  variable's  description  and  default  values with your region of choice.  The current list of available GCP regions may be found at  https://cloud.google.com/about/locations/ .  The  gcp_credentials_file , and  gcp_ssh_key  variables have been pre-populated for you.  variable \"gcp_project_id\" {\n  description = \"GCP Project ID\"\n  type = \"string\"\n  default = \"\"\n}\n\nvariable \"gcp_region\" {\n  description = \"\"\n  type = \"string\"\n  default = \"\"\n}\n\nvariable \"gcp_credentials_file\" {\n  description = \"Full path to the JSON credentials file\"\n  type = \"string\"\n  default = \"../gcp_compute_key.json\"\n}\n\nvariable \"gcp_ssh_key\" {\n  description = \"Full path to the SSH public key file\"\n  type = \"string\"\n  default = \"../../.ssh/lab_ssh_key.pub\"\n}  Save the file and exit the text editor.",
            "title": "Define the Terraform plan variables"
        },
        {
            "location": "/deployment/#initialize-the-terraform-providers",
            "text": "Type the following command to initialize any Terraform providers specified in the plan files.  $ terraform init",
            "title": "Initialize the Terraform providers"
        },
        {
            "location": "/deployment/#deploy-the-vm-series-firewall",
            "text": "Type the following command to perform a dry-run of the Terraform plan and gather its state data.  $ terraform plan  Type the following command to execute the Terraform plan.  You can append  --auto-approve  to the command in order to avoid the confirmation step.  This will deploy the VM-Series instance in GCP.  This will take a few moments to complete.  $ terraform apply  Copy and paste the output fields (in green) into a note or document on your laptop.  You will need this information later.",
            "title": "Deploy the VM-Series firewall"
        },
        {
            "location": "/deployment/#update-the-ssh-config",
            "text": "Use the following  gcloud compute  command to override the default GCP key management process and utilize our SSH key.  $ gcloud compute config-ssh --ssh-key-file=~/.ssh/lab_ssh_key",
            "title": "Update the SSH config"
        },
        {
            "location": "/deployment/#set-the-firewall-administrator-password",
            "text": "Use the  gcloud compute  command to get the hostname of the VM-Series firewall instance.  $ gcloud compute instances list  SSH into the firewall using the fully qualified hostname of the instance.  You may need to wait a few minutes for the firewall to finish booting up. If you receive a  Connection refused  response or are prompted for a password the VM-Series instance has not fully booted yet. Hit  Ctl-C  and wait few moments before trying again.   NOTE:  Feel free to read the  Terraform Background  section to learn more about Terraform while you're waiting. :-)   $ ssh admin@<INSTANCE>.<ZONE>.<PROJECT>  Once successfully logged in and presented with a CLI prompt you must set the administrative password for the VM-Series firewall.  admin@PA-VM> configure\nadmin@PA-VM# set mgt-config users admin password\nadmin@PA-VM# commit\nadmin@PA-VM# exit\nadmin@PA-VM> exit  Launch a separate web browser tab and log into the VM-Series web user interface using the external IP address of the VM-Series instance.  You are now ready to begin the Terraform portion of the lab.",
            "title": "Set the firewall administrator password"
        },
        {
            "location": "/terraform-background/",
            "text": "Terraform Background\n\n\nTerraform At a Glance\n\n\n\n\nCompany:  \nHashiCorp\n\n\nIntegration FCS: January 2018\n\n\nConfiguration: HCL (HashiCorp Configuration Language)\n\n\nDocumentation\n\n\nGitHub Repo\n\n\nImplementation Language: golang\n\n\n\n\nConfiguration Overview\n\n\nMany Files, One Configuration\n\n\nTerraform allows you to split your configuration into as many files as you\nwish.  Any Terraform file in the current working directory will be loaded and\nconcatenated with the others when you tell Terraform to apply your desired\nconfiguration.\n\n\nLocal State\n\n\nTerraform saves the things it has done to a local file, referred to as a\n\"state file\".  Because state is saved locally, that means that sometimes the\nlocal state will differ from what's actually configured on the firewall.\n\n\nThis is actually not a big deal, as many of Terraform's commands do a Read\noperation to check the actual state against what's saved locally.  Any\nchanges that are found are then saved to the local state automatically.\n\n\nExample Terraform Configuration\n\n\nHere's an example of a Terraform configuration file.  We will discuss the\nparts of this config below.\n\n\nvariable \"hostname\" {\n    default = \"127.0.0.1\"\n}\n\nvariable \"username\" {\n    default = \"admin\"\n}\n\nvariable \"password\" {\n    default = \"admin\"\n}\n\nprovider \"panos\" {\n    hostname = \"${var.hostname}\"\n    username = \"${var.username}\"\n    password = \"${var.password}\"\n}\n\nresource \"panos_management_profile\" \"ssh\" {\n    name = \"allow ssh\"\n    ssh = true\n}\n\nresource \"panos_ethernet_interface\" \"eth1\" {\n    name = \"ethernet1/1\"\n    vsys = \"vsys1\"\n    mode = \"layer3\"\n    enable_dhcp = true\n    management_profile = \"${panos_management_profile.ssh.name}\"\n}\n\nresource \"panos_zone\" \"zone1\" {\n    name = \"L3-in\"\n    mode = \"layer3\"\n    interfaces = [\"ethernet1/1\"]\n    depends_on = [\"panos_ethernet_interface.eth1\"]\n}\n\n\n\n\nTerminology\n\n\nPlan\n\n\nA Terraform \nplan\n is the sum of all Terraform configuration files\nin a given directory.  These files are generally written in \nHCL\n.\n\n\nProvider\n\n\nA \nprovider\n can loosely thought of to be a product (such as the Palo Alto \nNetworks firewall) or a service (such as AWS, Azure, or GCP).  The provider \nunderstands the underlying API to the product or service, making individual \nparts of those things available as \nresources\n.\n\n\nMost providers require some kind of configuration in order to use.  For the\n\npanos\n provider, this is the authentication credentials of the firewall or\nPanorama that you want to configure.\n\n\nProviders are configured in a provider configuration block (e.g. -\n\nprovider \"panos\" {...}\n, and a plan can make use of any number of providers,\nall working together.\n\n\nResource\n\n\nA \nresource\n is an individual component that a provider supports \ncreate/read/update/delete operations for.\n\n\nFor the Palo Alto Networks firewall, this would be something like\nan ethernet interface, service object, or an interface management profile.\n\n\nData Source\n\n\nA \ndata source\n is like a resource, but read-only.\n\n\nFor example, the \npanos\n provider has\n\na data source\n\nthat gives you access to the results of \nshow system info\n.\n\n\nAttribute\n\n\nAn \nattribute\n is a single parameter that exists in either a resource or a \ndata source.  Individual attributes are specific to the resource itself, as to \nwhat type it is, if it's required or optional, has a default value, or if \nchanging it would require the whole resource to be recreated or not.\n\n\nAttributes can have a few different types:\n\n\n\n\nString\n:  \n\"foo\"\n, \n\"bar\"\n\n\nNumber\n: \n7\n, \n\"42\"\n (quoting numbers is fine in HCL)\n\n\nList\n: \n[\"item1\", \"item2\"]\n\n\nBoolean\n: \ntrue\n, \nfalse\n\n\nMap\n: \n{\"key\": \"value\"}\n (\nNote\n: some maps may have more complex values)\n\n\n\n\nVariables\n\n\nTerraform plans can have \nvariables\n to allow for more flexibility.  These \nvariables come in two flavors:  user variables and attribute variables.\n\nWhenever you want to use variables (or any other Terraform interpolation), \nyou'll be enclosing it in curly braces with a leading dollar sign:  \n\"${...}\"\n\n\nUser variables are variables that are defined in the Terraform plan file\nwith the \nvariable\n keyword.  These can be any of the types of values that\nattributes can be (default is string), and can also be configured to have\ndefault values.  When using a user variable in your plan files, they are\nreferenced with \nvar\n as a prefix: \n\"${var.hostname}\"\n.  Terraform looks for\nlocal variable values in the file \nterraform.tfvars\n.\n\n\nAttribute variables are variables that reference other resources or data\nsources within the same plan.  Specifying a resource attribute using an\nattribute variable creates an implicit dependency, covered below.\n\n\nDependencies\n\n\nThere are two ways to tell Terraform that resource \"A\" needs to be created\nbefore resource \"B\":  the universal \ndepends_on\n resource parameter or an\nattribute variable.  The first way, using \ndepends_on\n, is performed by\nadding the universal parameter \"depends_on\" within the dependent\nresource.  The second way, using attribute variables, is performed by\nreferencing a resource or data source attribute as a variable:\n\n\"${panos_management_profile.ssh.name}\"\n\n\nCommon Commands\n\n\nThe Terraform binary has many different CLI arguments that it supports.  We'll\ndiscuss only a few of them here:\n\n\n$ terraform init\n\n\n\n\nterraform init\n initializes the current directory based off of the local plan files, \ndownloading any missing provider binaries.\n\n\n$ terraform plan\n\n\n\n\nterraform plan\n refreshes provider/resource states and reports what changes \nneed to take place.\n\n\n$ terraform apply\n\n\n\n\nterraform apply\n refreshes provider/resource states and makes any needed \nchanges to the resources.\n\n\n$ terraform destroy\n\n\n\n\nterraform destroy\n refreshes provider/resource states and removes all \nresources that Terraform created.",
            "title": "Background"
        },
        {
            "location": "/terraform-background/#terraform-background",
            "text": "",
            "title": "Terraform Background"
        },
        {
            "location": "/terraform-background/#terraform-at-a-glance",
            "text": "Company:   HashiCorp  Integration FCS: January 2018  Configuration: HCL (HashiCorp Configuration Language)  Documentation  GitHub Repo  Implementation Language: golang",
            "title": "Terraform At a Glance"
        },
        {
            "location": "/terraform-background/#configuration-overview",
            "text": "",
            "title": "Configuration Overview"
        },
        {
            "location": "/terraform-background/#many-files-one-configuration",
            "text": "Terraform allows you to split your configuration into as many files as you\nwish.  Any Terraform file in the current working directory will be loaded and\nconcatenated with the others when you tell Terraform to apply your desired\nconfiguration.",
            "title": "Many Files, One Configuration"
        },
        {
            "location": "/terraform-background/#local-state",
            "text": "Terraform saves the things it has done to a local file, referred to as a\n\"state file\".  Because state is saved locally, that means that sometimes the\nlocal state will differ from what's actually configured on the firewall.  This is actually not a big deal, as many of Terraform's commands do a Read\noperation to check the actual state against what's saved locally.  Any\nchanges that are found are then saved to the local state automatically.",
            "title": "Local State"
        },
        {
            "location": "/terraform-background/#example-terraform-configuration",
            "text": "Here's an example of a Terraform configuration file.  We will discuss the\nparts of this config below.  variable \"hostname\" {\n    default = \"127.0.0.1\"\n}\n\nvariable \"username\" {\n    default = \"admin\"\n}\n\nvariable \"password\" {\n    default = \"admin\"\n}\n\nprovider \"panos\" {\n    hostname = \"${var.hostname}\"\n    username = \"${var.username}\"\n    password = \"${var.password}\"\n}\n\nresource \"panos_management_profile\" \"ssh\" {\n    name = \"allow ssh\"\n    ssh = true\n}\n\nresource \"panos_ethernet_interface\" \"eth1\" {\n    name = \"ethernet1/1\"\n    vsys = \"vsys1\"\n    mode = \"layer3\"\n    enable_dhcp = true\n    management_profile = \"${panos_management_profile.ssh.name}\"\n}\n\nresource \"panos_zone\" \"zone1\" {\n    name = \"L3-in\"\n    mode = \"layer3\"\n    interfaces = [\"ethernet1/1\"]\n    depends_on = [\"panos_ethernet_interface.eth1\"]\n}",
            "title": "Example Terraform Configuration"
        },
        {
            "location": "/terraform-background/#terminology",
            "text": "",
            "title": "Terminology"
        },
        {
            "location": "/terraform-background/#plan",
            "text": "A Terraform  plan  is the sum of all Terraform configuration files\nin a given directory.  These files are generally written in  HCL .",
            "title": "Plan"
        },
        {
            "location": "/terraform-background/#provider",
            "text": "A  provider  can loosely thought of to be a product (such as the Palo Alto \nNetworks firewall) or a service (such as AWS, Azure, or GCP).  The provider \nunderstands the underlying API to the product or service, making individual \nparts of those things available as  resources .  Most providers require some kind of configuration in order to use.  For the panos  provider, this is the authentication credentials of the firewall or\nPanorama that you want to configure.  Providers are configured in a provider configuration block (e.g. - provider \"panos\" {...} , and a plan can make use of any number of providers,\nall working together.",
            "title": "Provider"
        },
        {
            "location": "/terraform-background/#resource",
            "text": "A  resource  is an individual component that a provider supports \ncreate/read/update/delete operations for.  For the Palo Alto Networks firewall, this would be something like\nan ethernet interface, service object, or an interface management profile.",
            "title": "Resource"
        },
        {
            "location": "/terraform-background/#data-source",
            "text": "A  data source  is like a resource, but read-only.  For example, the  panos  provider has a data source \nthat gives you access to the results of  show system info .",
            "title": "Data Source"
        },
        {
            "location": "/terraform-background/#attribute",
            "text": "An  attribute  is a single parameter that exists in either a resource or a \ndata source.  Individual attributes are specific to the resource itself, as to \nwhat type it is, if it's required or optional, has a default value, or if \nchanging it would require the whole resource to be recreated or not.  Attributes can have a few different types:   String :   \"foo\" ,  \"bar\"  Number :  7 ,  \"42\"  (quoting numbers is fine in HCL)  List :  [\"item1\", \"item2\"]  Boolean :  true ,  false  Map :  {\"key\": \"value\"}  ( Note : some maps may have more complex values)",
            "title": "Attribute"
        },
        {
            "location": "/terraform-background/#variables",
            "text": "Terraform plans can have  variables  to allow for more flexibility.  These \nvariables come in two flavors:  user variables and attribute variables. \nWhenever you want to use variables (or any other Terraform interpolation), \nyou'll be enclosing it in curly braces with a leading dollar sign:   \"${...}\"  User variables are variables that are defined in the Terraform plan file\nwith the  variable  keyword.  These can be any of the types of values that\nattributes can be (default is string), and can also be configured to have\ndefault values.  When using a user variable in your plan files, they are\nreferenced with  var  as a prefix:  \"${var.hostname}\" .  Terraform looks for\nlocal variable values in the file  terraform.tfvars .  Attribute variables are variables that reference other resources or data\nsources within the same plan.  Specifying a resource attribute using an\nattribute variable creates an implicit dependency, covered below.",
            "title": "Variables"
        },
        {
            "location": "/terraform-background/#dependencies",
            "text": "There are two ways to tell Terraform that resource \"A\" needs to be created\nbefore resource \"B\":  the universal  depends_on  resource parameter or an\nattribute variable.  The first way, using  depends_on , is performed by\nadding the universal parameter \"depends_on\" within the dependent\nresource.  The second way, using attribute variables, is performed by\nreferencing a resource or data source attribute as a variable: \"${panos_management_profile.ssh.name}\"",
            "title": "Dependencies"
        },
        {
            "location": "/terraform-background/#common-commands",
            "text": "The Terraform binary has many different CLI arguments that it supports.  We'll\ndiscuss only a few of them here:  $ terraform init  terraform init  initializes the current directory based off of the local plan files, \ndownloading any missing provider binaries.  $ terraform plan  terraform plan  refreshes provider/resource states and reports what changes \nneed to take place.  $ terraform apply  terraform apply  refreshes provider/resource states and makes any needed \nchanges to the resources.  $ terraform destroy  terraform destroy  refreshes provider/resource states and removes all \nresources that Terraform created.",
            "title": "Common Commands"
        },
        {
            "location": "/terraform-lab/",
            "text": "Terraform Lab Activities\n\n\nIn this activity you will:\n\n\n\n\nPerform basic network configuration\n\n\nCreate objects and security rules\n\n\nClean up the firewall configs\n\n\n\n\nTask 1 - Basic Networking Config\n\n\nChange into the \nterraform\n directory.  We'll use it for all of our Terraform files.\n\n\n$ cd ../terraform\n\n\n\n\nEdit the file \npanos_variables.tf\n and replace the \ndefault\n values of the variables \npanos_hostname\n, \npanos_username\n, and \npanos_password\n with the appropriate values from your VM-Series instance.\n\n\nvariable \"panos_hostname\" {\n  description = \"The external IP address of the VM-Series instance\"\n  type = \"string\"\n  default = \"\"\n}\n\nvariable \"panos_username\" {\n  description = \"Username of the VM-Series administrator\"\n  type = \"string\"\n  default = \"\"\n}\n\nvariable \"panos_password\" {\n  description = \"Password of the VM-Series administrator\"\n  type = \"string\"\n  default = \"\"\n}\n\n\n\n\nUsing your text editor create the file \npanos_plan.tf\n.  We will place our Terraform plan in this file.\n\n\nStart by defining the provider config, which will use the \npanos\n provider. Note that the \nhostname\n, \nusername\n, and \npassword\n fields refer to the variables we defined in the \npanos_variables.tf\n file.\n\n\nprovider \"panos\" {\n    hostname = \"${var.panos_hostname}\"\n    username = \"${var.panos_username}\"\n    password = \"${var.panos_password}\"\n}\n\n\n\n\nNetwork Interfaces\n\n\nNext, we will create the interfaces resources.  Here are examples of the interfaces we will be creating:\n\n\n\n\n\n\nAdd the following resources to \npanos_plan.tf\n.  Note that the \nethernet1/2\n interface omits the option to create the default route via DHCP.\n\n\nresource \"panos_ethernet_interface\" \"eth1\" {\n    name = \"ethernet1/1\"\n    vsys = \"vsys1\"\n    mode = \"layer3\"\n    enable_dhcp = true\n    create_dhcp_default_route = true\n}\n\nresource \"panos_ethernet_interface\" \"eth2\" {\n    name = \"ethernet1/2\"\n    vsys = \"vsys1\"\n    mode = \"layer3\"\n    enable_dhcp = true\n}\n\n\n\n\nRefer to the \nprovider documentation\n for more details on the \npanos_ethernet_interface\n resource.\n\n\nVirtual Router\n\n\nNow we have to associate these interfaces with the default virtual router.  Add the following configuration to \npanos_plan.tf\n.  The interfaces are referenced by name so that Terraform automatically knows that the interfaces will need to be created \nbefore\n the virtual router resource.\n\n\nresource \"panos_virtual_router\" \"vr\" {\n    name = \"default\"\n    interfaces = [\n        \"${panos_ethernet_interface.eth1.name}\",\n        \"${panos_ethernet_interface.eth2.name}\"\n    ]\n}\n\n\n\n\nRefer to the \nprovider documentation\n for more details on the \npanos_virtual_router\n resource.\n\n\nZones\n\n\nNext, we will create resources for security zones and reference the interfaces we added.  Here are examples of the zones we need to create:\n\n\n\n\n\n\nAdd the following configuration to \npanos_plan.tf\n.  The interfaces are referenced by name so that Terraform automatically knows that the interfaces will need to be created \nbefore\n the zones themselves.\n\n\nresource \"panos_zone\" \"int\" {\n    name = \"L3-trust\"\n    mode = \"layer3\"\n    interfaces = [\"${panos_ethernet_interface.eth1.name}\"]\n}\n\nresource \"panos_zone\" \"ext\" {\n    name = \"L3-untrust\"\n    mode = \"layer3\"\n    interfaces = [\"${panos_ethernet_interface.eth2.name}\"]\n}\n\n\n\n\nRefer to the \nprovider documentation\n for more details on the \npanos_zone\n resource.\n\n\nApply the Terraform Plan\n\n\nThe resulting \npanos_plan.tf\n file should look like this:\n\n\nprovider \"panos\" {\n    hostname = \"${var.panos_hostname}\"\n    username = \"${var.panos_username}\"\n    password = \"${var.panos_password}\"\n}\n\nresource \"panos_ethernet_interface\" \"eth1\" {\n    name = \"ethernet1/1\"\n    vsys = \"vsys1\"\n    mode = \"layer3\"\n    enable_dhcp = true\n    create_dhcp_default_route = true\n}\n\nresource \"panos_ethernet_interface\" \"eth2\" {\n    name = \"ethernet1/2\"\n    vsys = \"vsys1\"\n    mode = \"layer3\"\n    enable_dhcp = true\n}\n\nresource \"panos_virtual_router\" \"vr\" {\n    name = \"default\"\n    interfaces = [\n        \"${panos_ethernet_interface.eth1.name}\",\n        \"${panos_ethernet_interface.eth2.name}\"\n    ]\n}\n\nresource \"panos_zone\" \"int\" {\n    name = \"L3-trust\"\n    mode = \"layer3\"\n    interfaces = [\"${panos_ethernet_interface.eth1.name}\"]\n}\n\nresource \"panos_zone\" \"ext\" {\n    name = \"L3-untrust\"\n    mode = \"layer3\"\n    interfaces = [\"${panos_ethernet_interface.eth2.name}\"]\n}\n\n\n\n\nLet's apply this config to our firewall.  You first need to run \nterraform init\n to download all the providers we need.\n\n\n$ terraform init\n\n\n\n\nWe'll then validate the config with \nterraform plan\n.\n\n\n$ terraform plan\n\n\n\n\nIf there are no errors, go ahead and push your config updates to the firewall with \nterraform apply\n.\n\n\n$ terraform apply\n\n\n\n\nLog in to the web UI of your firewall and verify that the configuration matches the examples above.  Note that because of the way Terraform \ncurrently\n functions the changes have only been made to the candidate configuration and have \nnot\n been committed.\n\n\n\n\nTask 2 - Objects and Security Rule Creation\n\n\nNext, we will create resources for an address object and some security rules. Here is an example of an address object we need to create:\n\n\n\n\nAdd the following to the bottom of the \npanos_plan.tf\n file:\n\n\nresource \"panos_address_object\" \"wp\" {\n    name = \"WordPress server\"\n    description = \"Internal server\"\n    value = \"10.1.23.45\"\n}\n\n\n\n\nRefer to the \nprovider documentation\n for more details on the \npanos_address_object\n resource.\n\n\nNow, here is an example of the security rules that we need to create:\n\n\n\n\nAdd the following to your \npanos_plan.tf\n file.  Just like with the networking config, zones and objects are referenced by name so that Terraform knows they need to be created before our security rules.\n\n\nresource \"panos_security_rule_group\" \"policy\" {\n    rule {\n        name = \"WordPress Traffic\"\n        source_zones = [\"${panos_zone.ext.name}\"]\n        source_addresses = [\"any\"]\n        source_users = [\"any\"]\n        hip_profiles = [\"any\"]\n        destination_zones = [\"${panos_zone.int.name}\"]\n        destination_addresses = [\"any\"]\n        applications = [\"web-browsing\"]\n        services = [\"application-default\"]\n        categories = [\"any\"]\n        action = \"allow\"\n    }\n    rule {\n        name = \"Outbound\"\n        source_zones = [\"${panos_zone.int.name}\"]\n        source_addresses = [\"any\"]\n        source_users = [\"any\"]\n        hip_profiles = [\"any\"]\n        destination_zones = [\"${panos_zone.ext.name}\"]\n        destination_addresses = [\"any\"]\n        applications = [\"any\"]\n        services = [\"application-default\"]\n        categories = [\"any\"]\n        action = \"allow\"\n    }\n    rule {\n        name = \"Default Deny\"\n        source_zones = [\"any\"]\n        source_addresses = [\"any\"]\n        source_users = [\"any\"]\n        hip_profiles = [\"any\"]\n        destination_zones = [\"any\"]\n        destination_addresses = [\"any\"]\n        applications = [\"any\"]\n        services = [\"application-default\"]\n        categories = [\"any\"]\n        action = \"deny\"\n    }\n}\n\n\n\n\nApply the Terraform Plan\n\n\nLet's apply the config to our firewall.  We won't need to run \nterraform init\n again since the provider has already been initialized. So just check your config with \nterraform plan\n:\n\n\n$ terraform plan\n\n\n\n\nIf there are no errors, go ahead and push your config updates to the firewall with \nterraform apply\n.\n\n\n$ terraform apply\n\n\n\n\nSwitch browser tabs to the web UI of your firewall and verify that the configuration matches the examples above.  Again, the changes have only been made to the candidate configuration and have \nnot\n been committed.\n\n\n\n\nTask 3 - Cleanup\n\n\nTerraform will clean up our firewall configs with the \nterraform destroy\n command. Run it to prepare for the Ansible portion of the lab:\n\n\n$ terraform destroy\n\n\n\n\nConfirm in the firewall UI that the security rules, objects, and network configs we created have been removed.\n\n\nYou're now done with the Terraform portion of the lab.",
            "title": "Lab Activities"
        },
        {
            "location": "/terraform-lab/#terraform-lab-activities",
            "text": "In this activity you will:   Perform basic network configuration  Create objects and security rules  Clean up the firewall configs",
            "title": "Terraform Lab Activities"
        },
        {
            "location": "/terraform-lab/#task-1-basic-networking-config",
            "text": "Change into the  terraform  directory.  We'll use it for all of our Terraform files.  $ cd ../terraform  Edit the file  panos_variables.tf  and replace the  default  values of the variables  panos_hostname ,  panos_username , and  panos_password  with the appropriate values from your VM-Series instance.  variable \"panos_hostname\" {\n  description = \"The external IP address of the VM-Series instance\"\n  type = \"string\"\n  default = \"\"\n}\n\nvariable \"panos_username\" {\n  description = \"Username of the VM-Series administrator\"\n  type = \"string\"\n  default = \"\"\n}\n\nvariable \"panos_password\" {\n  description = \"Password of the VM-Series administrator\"\n  type = \"string\"\n  default = \"\"\n}  Using your text editor create the file  panos_plan.tf .  We will place our Terraform plan in this file.  Start by defining the provider config, which will use the  panos  provider. Note that the  hostname ,  username , and  password  fields refer to the variables we defined in the  panos_variables.tf  file.  provider \"panos\" {\n    hostname = \"${var.panos_hostname}\"\n    username = \"${var.panos_username}\"\n    password = \"${var.panos_password}\"\n}",
            "title": "Task 1 - Basic Networking Config"
        },
        {
            "location": "/terraform-lab/#network-interfaces",
            "text": "Next, we will create the interfaces resources.  Here are examples of the interfaces we will be creating:    Add the following resources to  panos_plan.tf .  Note that the  ethernet1/2  interface omits the option to create the default route via DHCP.  resource \"panos_ethernet_interface\" \"eth1\" {\n    name = \"ethernet1/1\"\n    vsys = \"vsys1\"\n    mode = \"layer3\"\n    enable_dhcp = true\n    create_dhcp_default_route = true\n}\n\nresource \"panos_ethernet_interface\" \"eth2\" {\n    name = \"ethernet1/2\"\n    vsys = \"vsys1\"\n    mode = \"layer3\"\n    enable_dhcp = true\n}  Refer to the  provider documentation  for more details on the  panos_ethernet_interface  resource.",
            "title": "Network Interfaces"
        },
        {
            "location": "/terraform-lab/#virtual-router",
            "text": "Now we have to associate these interfaces with the default virtual router.  Add the following configuration to  panos_plan.tf .  The interfaces are referenced by name so that Terraform automatically knows that the interfaces will need to be created  before  the virtual router resource.  resource \"panos_virtual_router\" \"vr\" {\n    name = \"default\"\n    interfaces = [\n        \"${panos_ethernet_interface.eth1.name}\",\n        \"${panos_ethernet_interface.eth2.name}\"\n    ]\n}  Refer to the  provider documentation  for more details on the  panos_virtual_router  resource.",
            "title": "Virtual Router"
        },
        {
            "location": "/terraform-lab/#zones",
            "text": "Next, we will create resources for security zones and reference the interfaces we added.  Here are examples of the zones we need to create:    Add the following configuration to  panos_plan.tf .  The interfaces are referenced by name so that Terraform automatically knows that the interfaces will need to be created  before  the zones themselves.  resource \"panos_zone\" \"int\" {\n    name = \"L3-trust\"\n    mode = \"layer3\"\n    interfaces = [\"${panos_ethernet_interface.eth1.name}\"]\n}\n\nresource \"panos_zone\" \"ext\" {\n    name = \"L3-untrust\"\n    mode = \"layer3\"\n    interfaces = [\"${panos_ethernet_interface.eth2.name}\"]\n}  Refer to the  provider documentation  for more details on the  panos_zone  resource.",
            "title": "Zones"
        },
        {
            "location": "/terraform-lab/#apply-the-terraform-plan",
            "text": "The resulting  panos_plan.tf  file should look like this:  provider \"panos\" {\n    hostname = \"${var.panos_hostname}\"\n    username = \"${var.panos_username}\"\n    password = \"${var.panos_password}\"\n}\n\nresource \"panos_ethernet_interface\" \"eth1\" {\n    name = \"ethernet1/1\"\n    vsys = \"vsys1\"\n    mode = \"layer3\"\n    enable_dhcp = true\n    create_dhcp_default_route = true\n}\n\nresource \"panos_ethernet_interface\" \"eth2\" {\n    name = \"ethernet1/2\"\n    vsys = \"vsys1\"\n    mode = \"layer3\"\n    enable_dhcp = true\n}\n\nresource \"panos_virtual_router\" \"vr\" {\n    name = \"default\"\n    interfaces = [\n        \"${panos_ethernet_interface.eth1.name}\",\n        \"${panos_ethernet_interface.eth2.name}\"\n    ]\n}\n\nresource \"panos_zone\" \"int\" {\n    name = \"L3-trust\"\n    mode = \"layer3\"\n    interfaces = [\"${panos_ethernet_interface.eth1.name}\"]\n}\n\nresource \"panos_zone\" \"ext\" {\n    name = \"L3-untrust\"\n    mode = \"layer3\"\n    interfaces = [\"${panos_ethernet_interface.eth2.name}\"]\n}  Let's apply this config to our firewall.  You first need to run  terraform init  to download all the providers we need.  $ terraform init  We'll then validate the config with  terraform plan .  $ terraform plan  If there are no errors, go ahead and push your config updates to the firewall with  terraform apply .  $ terraform apply  Log in to the web UI of your firewall and verify that the configuration matches the examples above.  Note that because of the way Terraform  currently  functions the changes have only been made to the candidate configuration and have  not  been committed.",
            "title": "Apply the Terraform Plan"
        },
        {
            "location": "/terraform-lab/#task-2-objects-and-security-rule-creation",
            "text": "Next, we will create resources for an address object and some security rules. Here is an example of an address object we need to create:   Add the following to the bottom of the  panos_plan.tf  file:  resource \"panos_address_object\" \"wp\" {\n    name = \"WordPress server\"\n    description = \"Internal server\"\n    value = \"10.1.23.45\"\n}  Refer to the  provider documentation  for more details on the  panos_address_object  resource.  Now, here is an example of the security rules that we need to create:   Add the following to your  panos_plan.tf  file.  Just like with the networking config, zones and objects are referenced by name so that Terraform knows they need to be created before our security rules.  resource \"panos_security_rule_group\" \"policy\" {\n    rule {\n        name = \"WordPress Traffic\"\n        source_zones = [\"${panos_zone.ext.name}\"]\n        source_addresses = [\"any\"]\n        source_users = [\"any\"]\n        hip_profiles = [\"any\"]\n        destination_zones = [\"${panos_zone.int.name}\"]\n        destination_addresses = [\"any\"]\n        applications = [\"web-browsing\"]\n        services = [\"application-default\"]\n        categories = [\"any\"]\n        action = \"allow\"\n    }\n    rule {\n        name = \"Outbound\"\n        source_zones = [\"${panos_zone.int.name}\"]\n        source_addresses = [\"any\"]\n        source_users = [\"any\"]\n        hip_profiles = [\"any\"]\n        destination_zones = [\"${panos_zone.ext.name}\"]\n        destination_addresses = [\"any\"]\n        applications = [\"any\"]\n        services = [\"application-default\"]\n        categories = [\"any\"]\n        action = \"allow\"\n    }\n    rule {\n        name = \"Default Deny\"\n        source_zones = [\"any\"]\n        source_addresses = [\"any\"]\n        source_users = [\"any\"]\n        hip_profiles = [\"any\"]\n        destination_zones = [\"any\"]\n        destination_addresses = [\"any\"]\n        applications = [\"any\"]\n        services = [\"application-default\"]\n        categories = [\"any\"]\n        action = \"deny\"\n    }\n}",
            "title": "Task 2 - Objects and Security Rule Creation"
        },
        {
            "location": "/terraform-lab/#apply-the-terraform-plan_1",
            "text": "Let's apply the config to our firewall.  We won't need to run  terraform init  again since the provider has already been initialized. So just check your config with  terraform plan :  $ terraform plan  If there are no errors, go ahead and push your config updates to the firewall with  terraform apply .  $ terraform apply  Switch browser tabs to the web UI of your firewall and verify that the configuration matches the examples above.  Again, the changes have only been made to the candidate configuration and have  not  been committed.",
            "title": "Apply the Terraform Plan"
        },
        {
            "location": "/terraform-lab/#task-3-cleanup",
            "text": "Terraform will clean up our firewall configs with the  terraform destroy  command. Run it to prepare for the Ansible portion of the lab:  $ terraform destroy  Confirm in the firewall UI that the security rules, objects, and network configs we created have been removed.  You're now done with the Terraform portion of the lab.",
            "title": "Task 3 - Cleanup"
        },
        {
            "location": "/ansible-background/",
            "text": "Ansible Background\n\n\nAnsible At a Glance\n\n\n\n\nCompany: \nRedHat\n\n\nIntegration FCS: January 2015\n\n\nConfiguration: YAML (Yet Another Markup Language)\n\n\nDocumentation\n\n\nGitHub Repo\n\n\nImplementation Language: python\n\n\n\n\nConfiguration Overview\n\n\nPlaybooks\n\n\nThough Ansible allows you to execute ad hoc commands against your desired\ninventory, the better way to use Ansible is with Ansible playbooks. \nAnsible playbooks are a list of configuration operations, or plays, to be\nperformed.  Ansible playbooks are written in YAML, which you can find out\nmore about\n\nhere\n. \nPlaybooks are run from top to bottom, which means that if one configuration\ndepends on another being present, you simply put the dependency higher in the\nplaybook.  You can even tell Ansible to run another playbook from within the\nfirst playbook by importing it in.\n\n\nNo Local State\n\n\nUnlike Terraform, Ansible does not keep a local state of what is configured.\n\n\nModules Are Use Case Focused\n\n\nAlso unlike the Terraform provider, Ansible modules tend to be more use case\nfocused as opposed to trying to be a single, atomic component controller.  The\n\npanos_interface\n\nmodule is probably the best example of this to date, as it not only creates\ninterfaces, but can also create zones, place the interface into that zone,\nthen finally put the interface into a virtual router.  That same workflow in\nTerraform would require three separate resources using dependencies.\n\n\nExample Ansible Configuration\n\n\nHere's an example of an Ansible playbook.  We will discuss the various\nparts of this below.\n\n\n- name: My Ansible Playbook\n  hosts: my-fw\n  connection: local\n  gather_facts: false\n\n  roles:\n    - role: PaloAltoNetworks.paloaltonetworks\n\n  tasks:\n  - name: Grab auth creds\n    include_vars: 'fw_creds.yml'\n    no_log: 'yes'\n\n  - name: \"Add interface management profile\"\n    panos_management_profile:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      name: 'allow ssh'\n      ssh: true\n      commit: false\n\n  - name: \"Configure eth1/1 and put it in zone L3-in\"\n    panos_interface:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      if_name: 'ethernet1/1'\n      zone_name: 'L3-in'\n      commit: false\n\n\n\n\nTerminology\n\n\nHosts\n\n\nAnsible executes actions against an inventory.  If you\u2019re going to run Ansible \nin production, you\u2019ll probably want to use the inventory file to organize your \nfirewalls and Panoramas into groups to make management easier.  For the \npurposes of our lab, however, we just want to run the playbooks against a \nsingle host.  So instead of putting the host in a hosts file, we\u2019re going to \nuse variables instead.\n\n\nIf you desire, you can read more about Ansible inventory\n\nhere\n.\n\n\nConnection\n\n\nTypically Ansible will ssh to a remote machine and perform commands as the \nspecified user account.  However, we don't want this for the Palo Alto Networks \nAnsible modules, as the modules connect to our API.  Thus this should be set to \n\"local\" as we want Ansible to initiate the connection locally.\n\n\nGather Facts\n\n\nAnsible facts are just information about remote nodes.  In our case, we aren\u2019t \ngoing to use facts for anything, so we\u2019re disabling them to ensure that our \nAnsible invocations are run in a timely manner (this is would probably not be \ndisabled in production).\n\n\nIf you want to read more about facts, you can find that info\n\nhere\n.\n\n\nRoles\n\n\nLet\u2019s discuss the \"PaloAltoNetworks.paloaltonetworks\" role that our playbook \nis using.  Ansible comes with various Palo Alto Networks packages when you \n\npip install ansible\n, but updating these packages takes a lot of time and \neffort.  In an effort to get new features to customers sooner, we've made \nnewer features available as an Ansible galaxy role.  Including this role in \nour playbook means that Ansible will use the role\u2019s code (the newest released \ncode) for the Ansible plays instead of the older code that's merged upstream \nwith Ansible.\n\n\nTasks\n\n\nEach playbook contains a list of tasks to perform.  These are executed in \norder, one at a time against the inventory.  Each task will have a \"name\", \nand this name is what shows up on the CLI when executing the Ansible playbook.\nBesides the name, you will specify the module to execute, and then an \nindented list of the values you want to pass in to that module.\n\n\nKnowing what you know about tasks, let\u2019s take a look at that \"include_vars\"\ntask.  At this point, knowing what the format of tasks is, you can now\nidentify \"include_vars\" as a module invocation (documentation for\n\"include_vars\" is\n\nhere\n). \n\n\nSo what\u2019s that \nno_log\n part?  This is simply to keep the authentication\ncredentials safe without compromising the verbosity of our Ansible output. \nYou can read more about that\n\nhere\n\nin the Ansible FAQs.\n\n\nDependencies\n\n\nAs mentioned previously, if you're using Ansible playbooks, then when you\nhave dependencies, simply place those further up in the playbook.",
            "title": "Background"
        },
        {
            "location": "/ansible-background/#ansible-background",
            "text": "",
            "title": "Ansible Background"
        },
        {
            "location": "/ansible-background/#ansible-at-a-glance",
            "text": "Company:  RedHat  Integration FCS: January 2015  Configuration: YAML (Yet Another Markup Language)  Documentation  GitHub Repo  Implementation Language: python",
            "title": "Ansible At a Glance"
        },
        {
            "location": "/ansible-background/#configuration-overview",
            "text": "",
            "title": "Configuration Overview"
        },
        {
            "location": "/ansible-background/#playbooks",
            "text": "Though Ansible allows you to execute ad hoc commands against your desired\ninventory, the better way to use Ansible is with Ansible playbooks. \nAnsible playbooks are a list of configuration operations, or plays, to be\nperformed.  Ansible playbooks are written in YAML, which you can find out\nmore about here . \nPlaybooks are run from top to bottom, which means that if one configuration\ndepends on another being present, you simply put the dependency higher in the\nplaybook.  You can even tell Ansible to run another playbook from within the\nfirst playbook by importing it in.",
            "title": "Playbooks"
        },
        {
            "location": "/ansible-background/#no-local-state",
            "text": "Unlike Terraform, Ansible does not keep a local state of what is configured.",
            "title": "No Local State"
        },
        {
            "location": "/ansible-background/#modules-are-use-case-focused",
            "text": "Also unlike the Terraform provider, Ansible modules tend to be more use case\nfocused as opposed to trying to be a single, atomic component controller.  The panos_interface \nmodule is probably the best example of this to date, as it not only creates\ninterfaces, but can also create zones, place the interface into that zone,\nthen finally put the interface into a virtual router.  That same workflow in\nTerraform would require three separate resources using dependencies.",
            "title": "Modules Are Use Case Focused"
        },
        {
            "location": "/ansible-background/#example-ansible-configuration",
            "text": "Here's an example of an Ansible playbook.  We will discuss the various\nparts of this below.  - name: My Ansible Playbook\n  hosts: my-fw\n  connection: local\n  gather_facts: false\n\n  roles:\n    - role: PaloAltoNetworks.paloaltonetworks\n\n  tasks:\n  - name: Grab auth creds\n    include_vars: 'fw_creds.yml'\n    no_log: 'yes'\n\n  - name: \"Add interface management profile\"\n    panos_management_profile:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      name: 'allow ssh'\n      ssh: true\n      commit: false\n\n  - name: \"Configure eth1/1 and put it in zone L3-in\"\n    panos_interface:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      if_name: 'ethernet1/1'\n      zone_name: 'L3-in'\n      commit: false",
            "title": "Example Ansible Configuration"
        },
        {
            "location": "/ansible-background/#terminology",
            "text": "",
            "title": "Terminology"
        },
        {
            "location": "/ansible-background/#hosts",
            "text": "Ansible executes actions against an inventory.  If you\u2019re going to run Ansible \nin production, you\u2019ll probably want to use the inventory file to organize your \nfirewalls and Panoramas into groups to make management easier.  For the \npurposes of our lab, however, we just want to run the playbooks against a \nsingle host.  So instead of putting the host in a hosts file, we\u2019re going to \nuse variables instead.  If you desire, you can read more about Ansible inventory here .",
            "title": "Hosts"
        },
        {
            "location": "/ansible-background/#connection",
            "text": "Typically Ansible will ssh to a remote machine and perform commands as the \nspecified user account.  However, we don't want this for the Palo Alto Networks \nAnsible modules, as the modules connect to our API.  Thus this should be set to \n\"local\" as we want Ansible to initiate the connection locally.",
            "title": "Connection"
        },
        {
            "location": "/ansible-background/#gather-facts",
            "text": "Ansible facts are just information about remote nodes.  In our case, we aren\u2019t \ngoing to use facts for anything, so we\u2019re disabling them to ensure that our \nAnsible invocations are run in a timely manner (this is would probably not be \ndisabled in production).  If you want to read more about facts, you can find that info here .",
            "title": "Gather Facts"
        },
        {
            "location": "/ansible-background/#roles",
            "text": "Let\u2019s discuss the \"PaloAltoNetworks.paloaltonetworks\" role that our playbook \nis using.  Ansible comes with various Palo Alto Networks packages when you  pip install ansible , but updating these packages takes a lot of time and \neffort.  In an effort to get new features to customers sooner, we've made \nnewer features available as an Ansible galaxy role.  Including this role in \nour playbook means that Ansible will use the role\u2019s code (the newest released \ncode) for the Ansible plays instead of the older code that's merged upstream \nwith Ansible.",
            "title": "Roles"
        },
        {
            "location": "/ansible-background/#tasks",
            "text": "Each playbook contains a list of tasks to perform.  These are executed in \norder, one at a time against the inventory.  Each task will have a \"name\", \nand this name is what shows up on the CLI when executing the Ansible playbook.\nBesides the name, you will specify the module to execute, and then an \nindented list of the values you want to pass in to that module.  Knowing what you know about tasks, let\u2019s take a look at that \"include_vars\"\ntask.  At this point, knowing what the format of tasks is, you can now\nidentify \"include_vars\" as a module invocation (documentation for\n\"include_vars\" is here ).   So what\u2019s that  no_log  part?  This is simply to keep the authentication\ncredentials safe without compromising the verbosity of our Ansible output. \nYou can read more about that here \nin the Ansible FAQs.",
            "title": "Tasks"
        },
        {
            "location": "/ansible-background/#dependencies",
            "text": "As mentioned previously, if you're using Ansible playbooks, then when you\nhave dependencies, simply place those further up in the playbook.",
            "title": "Dependencies"
        },
        {
            "location": "/ansible-lab/",
            "text": "Ansible Lab Activities\n\n\nIn this activity you will:\n\n\n\n\nSet up the initial configuration files\n\n\nPerform basic network configuration\n\n\nCreate objects and security rules\n\n\n\n\nTask 1 - Lab Setup\n\n\nChange into the \nansible\n directory.  We'll use it for all of our Ansible files.\n\n\n$ cd ../ansible\n\n\n\n\nThen, install the Palo Alto Networks Ansible Galaxy role:\n\n\n$ sudo ansible-galaxy install PaloAltoNetworks.paloaltonetworks\n\n\n\n\n\n\nTask 2 - Basic Network Config\n\n\nEdit the file called \ninventory\n with your text editor.  This file will contains a list of hosts and host groups that Ansible will communicate with during execution.\n\n\nFill in the blank \nip_address\n value with the external IP address of your VM-Series instance.\n\n\n---\nall:\n  hosts:\n    fw:\n      ansible_host: '127.0.0.1'\n      ip_address: ''\n\n\n\n\nNext, edit the file \nvars.yml\n and fill in the blank values with the appropriate values from your VM-Series instance.\n\n\n---\nusername: ''\npassword: ''\n\n\n\n\n\n\nNOTE:\n It's a very poor security practice to store administrative credentials in cleartext files.  We're only doing so in this lab for the sake of simplicity. Normally, you would want to use Ansible's Vault functionality to encrypt sensitive variables and decrypt them when playbooks are being run.  More information on Ansible Vault may be found \nhere\n.\n\n\n\n\nNow, create the file \nnetwork.yml\n.  This will be the playbook that holds the low level networking config for our firewall.\n\n\nEach playbook needs the following header information to pull in the variables we just defined.  Add the following to \nnetwork.yml\n:\n\n\n- name: Ansible Playbook\n  hosts: fw\n  connection: local\n  gather_facts: false\n\n  roles:\n    - role: PaloAltoNetworks.paloaltonetworks\n\n  tasks:\n  - name: Grab auth creds\n    include_vars: 'vars.yml'\n    no_log: 'yes'\n\n\n\n\n\n\nNOTE:\n Ansible configuration files utilize a format known as YAML (Yet Another Markup Language). Spacing is \nvery\n important when editing YAML files.  Please be sure when copying and pasting to include all spacing as well.  All of the task names and parameters should line up properly.\n\n\n\n\nNetwork Interfaces & Zones\n\n\nWe're going to recreate the same configuration from the Terraform lab in Ansible.  Here are examples of the network interfaces and zones we need to create:\n\n\n\n\n\n\n\n\n\n\nAdd the following to \nnetwork.yml\n:\n\n\n  - name: \"Configure eth1/1\"\n    panos_interface:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      if_name: 'ethernet1/1'\n      create_default_route: true\n      zone_name: 'L3-trust'\n      commit: False\n\n  - name: \"Configure eth1/2\"\n    panos_interface:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      if_name: 'ethernet1/2'\n      zone_name: 'L3-untrust'\n      commit: False\n\n\n\n\nRefer to the \nmodule documentation\n for details on the \npanos_ethernet\n module.\n\n\nNote that Ansible is a little different from Terraform.  We have to specify the \nip_address\n, \nusername\n, and \npassword\n each time because each module executes independently.  Also, we don't have to create the zones as a separate step because they will be created for us if they don't exist.\n\n\nRun the Playbook\n\n\nThe resulting \nnetwork.yml\n playbook should look like this:\n\n\n- name: My Ansible Playbook\n  hosts: fw\n  connection: local\n  gather_facts: false\n\n  roles:\n    - role: PaloAltoNetworks.paloaltonetworks\n\n  tasks:\n  - name: Grab auth creds\n    include_vars: 'vars.yml'\n    no_log: 'yes'\n\n  - name: Configure eth1/1\n    panos_interface:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      if_name: 'ethernet1/1'\n      create_default_route: true\n      zone_name: 'L3-trust'\n      commit: False\n\n  - name: Configure eth1/2\n    panos_interface:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      if_name: 'ethernet1/2'\n      zone_name: 'L3-untrust'\n      commit: False\n\n\n\n\nRun your playbook with the following command:\n\n\n$ ansible-playbook -i inventory network.yml\n\n\n\n\nLog in to the GUI of your firewall and verify that the configuration matches the examples above.  Because we specified \ncommit: False\n for each module call in our playbook, the changes have only been made to the candidate configuration and have \nnot\n been committed.\n\n\nIf you get errors, indentation is most likely the problem.  Once you fix any errors, run the playbook again and the firewall should now have your desired config.\n\n\n\n\nTask 3 - Objects and Security Rule Creation\n\n\nCreate a new file \nrules.yml\n, and add the same header information from the network config task.\n\n\n- name: SKO2019 Ansible Playbook\n  hosts: fw\n  connection: local\n  gather_facts: false\n\n  roles:\n    - role: PaloAltoNetworks.paloaltonetworks\n\n  tasks:\n  - name: Grab auth creds\n    include_vars: 'vars.yml'\n    no_log: 'yes'\n\n\n\n\nHere is an example of the address object we will create:\n\n\n\n\nAdd the following to \nrules.yml\n:\n\n\n  - name: Add address object for WordPress server\n    panos_object:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      addressobject: 'WordPress server'\n      address: '10.1.23.45'\n      description: 'Internal server'\n\n\n\n\nRefer to the \nmodule documentation\n for more details on the \npanos_object\n module.\n\n\nHere is an example of the security rules we will create:\n\n\n\n\nAdd the following to \nrules.yml\n:\n\n\n  - name: Add WordPress Traffic rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'WordPress Traffic'\n      source_zone: ['L3-untrust']\n      destination_zone: ['L3-trust']\n      destination_ip: ['WordPress server']\n      application: ['web-browsing']\n      action: 'allow'\n      commit: False\n\n  - name: Add Outbound rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'Outbound'\n      source_zone: ['L3-trust']\n      destination_zone: ['L3-untrust']\n      action: 'allow'\n      commit: False\n\n  - name: Add Default Deny rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'Default Deny'\n      action: 'deny'\n      commit: False\n\n\n\n\nRefer to the \nmodule documentation\n for more details on the \npanos_security_rule\n module.\n\n\nRun the Playbook\n\n\nYour final, full \nrules.yml\n playbook should look like this:\n\n\n- name: My Ansible Playbook\n  hosts: fw\n  connection: local\n  gather_facts: false\n\n  roles:\n    - role: PaloAltoNetworks.paloaltonetworks\n\n  tasks:\n  - name: Grab auth creds\n    include_vars: 'vars.yml'\n    no_log: 'yes'\n\n  - name: Add address object for WordPress server\n    panos_object:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      addressobject: 'WordPress server'\n      address: '10.1.23.45'\n      description: 'Internal server'\n\n  - name: Add WordPress Traffic rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'WordPress Traffic'\n      source_zone: ['L3-untrust']\n      destination_zone: ['L3-trust']\n      destination_ip: ['WordPress server']\n      application: ['web-browsing']\n      action: 'allow'\n      commit: False\n\n  - name: Add Outbound rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'Outbound'\n      source_zone: ['L3-trust']\n      destination_zone: ['L3-untrust']\n      action: 'allow'\n      commit: False\n\n  - name: Add Default Deny rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'Default Deny'\n      action: 'deny'\n      commit: False\n\n\n\n\nRun your playbook with the following command:\n\n\n$ ansible-playbook -i inventory rules.yml\n\n\n\n\nLog in to the web UI of the firewall and verify that the configuration matches the examples above.  Remember that your changes haven't been committed.  If you get errors indentation is most likely the problem.\n\n\nYou're done with the Ansible portion of the lab.",
            "title": "Lab Activities"
        },
        {
            "location": "/ansible-lab/#ansible-lab-activities",
            "text": "In this activity you will:   Set up the initial configuration files  Perform basic network configuration  Create objects and security rules",
            "title": "Ansible Lab Activities"
        },
        {
            "location": "/ansible-lab/#task-1-lab-setup",
            "text": "Change into the  ansible  directory.  We'll use it for all of our Ansible files.  $ cd ../ansible  Then, install the Palo Alto Networks Ansible Galaxy role:  $ sudo ansible-galaxy install PaloAltoNetworks.paloaltonetworks",
            "title": "Task 1 - Lab Setup"
        },
        {
            "location": "/ansible-lab/#task-2-basic-network-config",
            "text": "Edit the file called  inventory  with your text editor.  This file will contains a list of hosts and host groups that Ansible will communicate with during execution.  Fill in the blank  ip_address  value with the external IP address of your VM-Series instance.  ---\nall:\n  hosts:\n    fw:\n      ansible_host: '127.0.0.1'\n      ip_address: ''  Next, edit the file  vars.yml  and fill in the blank values with the appropriate values from your VM-Series instance.  ---\nusername: ''\npassword: ''   NOTE:  It's a very poor security practice to store administrative credentials in cleartext files.  We're only doing so in this lab for the sake of simplicity. Normally, you would want to use Ansible's Vault functionality to encrypt sensitive variables and decrypt them when playbooks are being run.  More information on Ansible Vault may be found  here .   Now, create the file  network.yml .  This will be the playbook that holds the low level networking config for our firewall.  Each playbook needs the following header information to pull in the variables we just defined.  Add the following to  network.yml :  - name: Ansible Playbook\n  hosts: fw\n  connection: local\n  gather_facts: false\n\n  roles:\n    - role: PaloAltoNetworks.paloaltonetworks\n\n  tasks:\n  - name: Grab auth creds\n    include_vars: 'vars.yml'\n    no_log: 'yes'   NOTE:  Ansible configuration files utilize a format known as YAML (Yet Another Markup Language). Spacing is  very  important when editing YAML files.  Please be sure when copying and pasting to include all spacing as well.  All of the task names and parameters should line up properly.",
            "title": "Task 2 - Basic Network Config"
        },
        {
            "location": "/ansible-lab/#network-interfaces-zones",
            "text": "We're going to recreate the same configuration from the Terraform lab in Ansible.  Here are examples of the network interfaces and zones we need to create:      Add the following to  network.yml :    - name: \"Configure eth1/1\"\n    panos_interface:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      if_name: 'ethernet1/1'\n      create_default_route: true\n      zone_name: 'L3-trust'\n      commit: False\n\n  - name: \"Configure eth1/2\"\n    panos_interface:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      if_name: 'ethernet1/2'\n      zone_name: 'L3-untrust'\n      commit: False  Refer to the  module documentation  for details on the  panos_ethernet  module.  Note that Ansible is a little different from Terraform.  We have to specify the  ip_address ,  username , and  password  each time because each module executes independently.  Also, we don't have to create the zones as a separate step because they will be created for us if they don't exist.",
            "title": "Network Interfaces &amp; Zones"
        },
        {
            "location": "/ansible-lab/#run-the-playbook",
            "text": "The resulting  network.yml  playbook should look like this:  - name: My Ansible Playbook\n  hosts: fw\n  connection: local\n  gather_facts: false\n\n  roles:\n    - role: PaloAltoNetworks.paloaltonetworks\n\n  tasks:\n  - name: Grab auth creds\n    include_vars: 'vars.yml'\n    no_log: 'yes'\n\n  - name: Configure eth1/1\n    panos_interface:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      if_name: 'ethernet1/1'\n      create_default_route: true\n      zone_name: 'L3-trust'\n      commit: False\n\n  - name: Configure eth1/2\n    panos_interface:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      if_name: 'ethernet1/2'\n      zone_name: 'L3-untrust'\n      commit: False  Run your playbook with the following command:  $ ansible-playbook -i inventory network.yml  Log in to the GUI of your firewall and verify that the configuration matches the examples above.  Because we specified  commit: False  for each module call in our playbook, the changes have only been made to the candidate configuration and have  not  been committed.  If you get errors, indentation is most likely the problem.  Once you fix any errors, run the playbook again and the firewall should now have your desired config.",
            "title": "Run the Playbook"
        },
        {
            "location": "/ansible-lab/#task-3-objects-and-security-rule-creation",
            "text": "Create a new file  rules.yml , and add the same header information from the network config task.  - name: SKO2019 Ansible Playbook\n  hosts: fw\n  connection: local\n  gather_facts: false\n\n  roles:\n    - role: PaloAltoNetworks.paloaltonetworks\n\n  tasks:\n  - name: Grab auth creds\n    include_vars: 'vars.yml'\n    no_log: 'yes'  Here is an example of the address object we will create:   Add the following to  rules.yml :    - name: Add address object for WordPress server\n    panos_object:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      addressobject: 'WordPress server'\n      address: '10.1.23.45'\n      description: 'Internal server'  Refer to the  module documentation  for more details on the  panos_object  module.  Here is an example of the security rules we will create:   Add the following to  rules.yml :    - name: Add WordPress Traffic rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'WordPress Traffic'\n      source_zone: ['L3-untrust']\n      destination_zone: ['L3-trust']\n      destination_ip: ['WordPress server']\n      application: ['web-browsing']\n      action: 'allow'\n      commit: False\n\n  - name: Add Outbound rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'Outbound'\n      source_zone: ['L3-trust']\n      destination_zone: ['L3-untrust']\n      action: 'allow'\n      commit: False\n\n  - name: Add Default Deny rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'Default Deny'\n      action: 'deny'\n      commit: False  Refer to the  module documentation  for more details on the  panos_security_rule  module.",
            "title": "Task 3 - Objects and Security Rule Creation"
        },
        {
            "location": "/ansible-lab/#run-the-playbook_1",
            "text": "Your final, full  rules.yml  playbook should look like this:  - name: My Ansible Playbook\n  hosts: fw\n  connection: local\n  gather_facts: false\n\n  roles:\n    - role: PaloAltoNetworks.paloaltonetworks\n\n  tasks:\n  - name: Grab auth creds\n    include_vars: 'vars.yml'\n    no_log: 'yes'\n\n  - name: Add address object for WordPress server\n    panos_object:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      addressobject: 'WordPress server'\n      address: '10.1.23.45'\n      description: 'Internal server'\n\n  - name: Add WordPress Traffic rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'WordPress Traffic'\n      source_zone: ['L3-untrust']\n      destination_zone: ['L3-trust']\n      destination_ip: ['WordPress server']\n      application: ['web-browsing']\n      action: 'allow'\n      commit: False\n\n  - name: Add Outbound rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'Outbound'\n      source_zone: ['L3-trust']\n      destination_zone: ['L3-untrust']\n      action: 'allow'\n      commit: False\n\n  - name: Add Default Deny rule\n    panos_security_rule:\n      ip_address: '{{ ip_address }}'\n      username: '{{ username }}'\n      password: '{{ password }}'\n      operation: 'add'\n      rule_name: 'Default Deny'\n      action: 'deny'\n      commit: False  Run your playbook with the following command:  $ ansible-playbook -i inventory rules.yml  Log in to the web UI of the firewall and verify that the configuration matches the examples above.  Remember that your changes haven't been committed.  If you get errors indentation is most likely the problem.  You're done with the Ansible portion of the lab.",
            "title": "Run the Playbook"
        },
        {
            "location": "/clean-up/",
            "text": "Clean Up\n\n\nIn this activity you will:\n\n\n\n\nDestroy the lab deployment\n\n\n\n\nDestroy the Deployment\n\n\nWhen deploying infrastructure in the public cloud it is important to tear it down when it is no longer needed.  Otherwise you will end up paying for services that are no longer needed. We'll need to go back to the deployment directory and use Terraform to destroy the VM-Series instance we deployed at the start of the lab.\n\n\nChange into the \ndeployment\n directory.\n\n\n$ cd ../deployment\n\n\n\n\nTell Terraform to destroy the contents of its plan files.\n\n\n$ terraform destroy\n\n\n\n\nDelete the GCP project with the following \ngcloud projects\n command.\n\n\n$ gcloud projects delete terraform-ansible-lab",
            "title": "Clean Up"
        },
        {
            "location": "/clean-up/#clean-up",
            "text": "In this activity you will:   Destroy the lab deployment",
            "title": "Clean Up"
        },
        {
            "location": "/clean-up/#destroy-the-deployment",
            "text": "When deploying infrastructure in the public cloud it is important to tear it down when it is no longer needed.  Otherwise you will end up paying for services that are no longer needed. We'll need to go back to the deployment directory and use Terraform to destroy the VM-Series instance we deployed at the start of the lab.  Change into the  deployment  directory.  $ cd ../deployment  Tell Terraform to destroy the contents of its plan files.  $ terraform destroy  Delete the GCP project with the following  gcloud projects  command.  $ gcloud projects delete terraform-ansible-lab",
            "title": "Destroy the Deployment"
        },
        {
            "location": "/comparison/",
            "text": "Comparing Terraform and Ansible\n\n\nAt this point, you've now used both Ansible and Terraform to configure a\nPalo Alto Networks firewall.  Though you've used these two tools to deploy\nthe same configuration, they differ in some important ways.  Let's discuss\nsome of those differences now.\n\n\nReputation\n\n\nBoth tools have a certain reputation associated with them.  Terraform is known\nmore for its power in deployment, while Ansible is known more for its\nflexibility in configuration.  Both products can do both jobs just fine.\n\n\nRegardless of their reputations, the most important part is that Palo Alto Networks\nhas integrations with both, and either way will get the job done.  It's\njust a matter of preference.\n\n\nIdempotence\n\n\nBoth Terraform and Ansible support \nidempotent\n\noperations.  Saying that an operation is idempotent means that applying it\nmultiple times will not change the result.  This is important for automation\ntools because they can be run to change configuration \nand\n also to verify\nthat the configuration actually matches what you want.  You can run\n\nterraform apply\n continuously for hours, and if your configuration matches\nwhat is defined in the plan, it won't actually change anything.\n\n\nHowever, the Palo Alto Networks Ansible modules do not currently support\nidempotent operation.  Most of the modules have an \noperation\n field which\ncan be \nadd\n, \nupdate\n or \ndelete\n.  Running the same playbook over again will\ncause a failure, because you can't add objects over top of themselves, or\ndelete ones that don't exist.  Supporting idempotent operations will be added\nto these modules in the future.\n\n\nCommits\n\n\nAs you've probably noticed, a lot of the Ansible modules allow you to commit\ndirectly from them.  There is also a dedicated Ansible module that just does\ncommits, containing support for both the firewall and Panorama.\n\n\nSo how do you perform commits with Terraform?  Currently, there is no support\nfor commits inside the Terraform ecosystem, so they have to be handled\nexternally.  Lack of finalizers are\n\na known shortcoming\n\nfor Terraform and, once it is addressed, support for it can be added to the\nprovider.  In the mean time, we provide\n\na golang script\n\nyou can use to fill the gap.\n\n\nOperational Commands\n\n\nAnsible currently has a \npanos_op\n module allows users to run arbitrary\noperational commands.  An operational command could be something that just\nshows some part of the configuration, but it can also change configuration.\nSince Ansible doesn't store state, it doesn't care what the invocation of\nthe \npanos_op\n module results in.\n\n\nThis is a different story in Terraform.  The basic flow of Terraform is that\nthere is a read operation that determines if a create, update, or delete needs\nto take place.  But operational commands as a whole don't fit as neatly into\nthis paradigm.  What if the operational command is just a read?  What if the\noperational command makes a configuration change, and should only be executed\nonce?  This uncertainty is why support for operational commands in Terraform\nis not currently in place.\n\n\nFacts / Data Sources\n\n\nTerraform may not have support for arbitrary operational commands, but it does\nhave a data source right now that you can retrieve specific parts of\n\nshow system info\n from the firewall or Panorama and then use that in your\nplan file.\n\n\nThis same thing is called \"facts\" in Ansible.  Some of our Ansible modules have\nsupport for an additional operation, \nfind\n, that acts in some ways like this,\nbut support for this is still being investigated or developed.\n\n\nFurther Reading\n\n\n\n\n\n\nTerraform\n\n\n\n\n\n\nTerraform Documentation\n\n\n\n\n\n\nTerraform panos Provider\n\n\n\n\n\n\nTerraform: Up & Running\n\n\n\n\n\n\n\n\n\n\nAnsible\n\n\n\n\n\n\nAnsible Docs\n\n\n\n\n\n\nansible-pan\n\n\n\n\n\n\nAnsible: Up & Running",
            "title": "Conclusion"
        },
        {
            "location": "/comparison/#comparing-terraform-and-ansible",
            "text": "At this point, you've now used both Ansible and Terraform to configure a\nPalo Alto Networks firewall.  Though you've used these two tools to deploy\nthe same configuration, they differ in some important ways.  Let's discuss\nsome of those differences now.",
            "title": "Comparing Terraform and Ansible"
        },
        {
            "location": "/comparison/#reputation",
            "text": "Both tools have a certain reputation associated with them.  Terraform is known\nmore for its power in deployment, while Ansible is known more for its\nflexibility in configuration.  Both products can do both jobs just fine.  Regardless of their reputations, the most important part is that Palo Alto Networks\nhas integrations with both, and either way will get the job done.  It's\njust a matter of preference.",
            "title": "Reputation"
        },
        {
            "location": "/comparison/#idempotence",
            "text": "Both Terraform and Ansible support  idempotent \noperations.  Saying that an operation is idempotent means that applying it\nmultiple times will not change the result.  This is important for automation\ntools because they can be run to change configuration  and  also to verify\nthat the configuration actually matches what you want.  You can run terraform apply  continuously for hours, and if your configuration matches\nwhat is defined in the plan, it won't actually change anything.  However, the Palo Alto Networks Ansible modules do not currently support\nidempotent operation.  Most of the modules have an  operation  field which\ncan be  add ,  update  or  delete .  Running the same playbook over again will\ncause a failure, because you can't add objects over top of themselves, or\ndelete ones that don't exist.  Supporting idempotent operations will be added\nto these modules in the future.",
            "title": "Idempotence"
        },
        {
            "location": "/comparison/#commits",
            "text": "As you've probably noticed, a lot of the Ansible modules allow you to commit\ndirectly from them.  There is also a dedicated Ansible module that just does\ncommits, containing support for both the firewall and Panorama.  So how do you perform commits with Terraform?  Currently, there is no support\nfor commits inside the Terraform ecosystem, so they have to be handled\nexternally.  Lack of finalizers are a known shortcoming \nfor Terraform and, once it is addressed, support for it can be added to the\nprovider.  In the mean time, we provide a golang script \nyou can use to fill the gap.",
            "title": "Commits"
        },
        {
            "location": "/comparison/#operational-commands",
            "text": "Ansible currently has a  panos_op  module allows users to run arbitrary\noperational commands.  An operational command could be something that just\nshows some part of the configuration, but it can also change configuration.\nSince Ansible doesn't store state, it doesn't care what the invocation of\nthe  panos_op  module results in.  This is a different story in Terraform.  The basic flow of Terraform is that\nthere is a read operation that determines if a create, update, or delete needs\nto take place.  But operational commands as a whole don't fit as neatly into\nthis paradigm.  What if the operational command is just a read?  What if the\noperational command makes a configuration change, and should only be executed\nonce?  This uncertainty is why support for operational commands in Terraform\nis not currently in place.",
            "title": "Operational Commands"
        },
        {
            "location": "/comparison/#facts-data-sources",
            "text": "Terraform may not have support for arbitrary operational commands, but it does\nhave a data source right now that you can retrieve specific parts of show system info  from the firewall or Panorama and then use that in your\nplan file.  This same thing is called \"facts\" in Ansible.  Some of our Ansible modules have\nsupport for an additional operation,  find , that acts in some ways like this,\nbut support for this is still being investigated or developed.",
            "title": "Facts / Data Sources"
        },
        {
            "location": "/comparison/#further-reading",
            "text": "Terraform    Terraform Documentation    Terraform panos Provider    Terraform: Up & Running      Ansible    Ansible Docs    ansible-pan    Ansible: Up & Running",
            "title": "Further Reading"
        }
    ]
}